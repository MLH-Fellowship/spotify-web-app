# SpotiME - MLH Fellowship Pod 3.3.0 Team 1
SpotiME is a react web app that uses spotify API and Machine Learning Emotion detection to recommend music to the users based on their emotion.
Once the user logs in with their spotify account, the website shows the summary of the user's music breakdown. 
The user can click the button "Play" to initiate a camera to capture the user's face (through front camera/webcam) which is analyzed by our ML model to detect the user's emotion. Based on the emotion detected, the user will receive a customized playlist by SpotiME!

## What it does üñ•
- Shows breakdown & summary of the user's spotify account
- Recommends a playlist based on the user's current emotion using Machine Learning emotion analyis

## How we built it üõ†
__To collaborate, we used:__
 - Git 
 - Discord chat / voice call

__To design the website, we used:__
 - Figma

__To build the website, we used:__
 - React 
 - Flask
 - [Spotify API](https://developer.spotify.com/documentation/web-api/)
 - ML Emotion Detection Library [FER](https://pypi.org/project/fer/)

__We deployed our website on:__
   - Heroku

__We tested it with:__
   - Github actions?

__We set up our database using:__
   - mongoDB?

## Challenges we ran into üò°
- Nginix
- Deployment memory issue

## Accomplishments that we're proud of üåü
- 
- 

## What we learned ‚úèÔ∏è
- 

## What's next
-

## Installation
- 
